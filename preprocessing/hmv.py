from difflib import get_close_matches
import pandas as pd
from utils.diccionarios import MARCAS_VALIDAS, MODELOS_POR_MARCA
from preprocessing.data_cleanse import normalizar, quitar_tildes
import re






def hmv_marca(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Marca' en df_to_input usando df_train como referencia.
    - Primero intenta imputar por fuzzy matching con 'Modelo' (cutoff alto)
    - Luego intenta con 'Versi√≥n' (cutoff alto)
    - Si falla, intenta fuzzy con cutoff m√°s bajo
    - Luego intenta detectar marca en 'T√≠tulo'
    - Si todo falla, elimina la fila
    Prints:
    - √çndices con marca faltante
    - Coincidencias encontradas y marcas asignadas
    - √çndices de filas eliminadas
    - Resumen final
    """
    df = df_to_input.copy()
    referencia = df_train[df_train['Marca'].notna()].copy()
    total_before = df.shape[0]

    df_missing = df[df['Marca'].isna()].copy()
    print(f"üîç √çndices con marca faltante: {[i + 2 for i in df_missing.index.tolist()]}")

    reemplazos = []
    for idx, row in df_missing.iterrows():
        marca_inferida = None
        modelo = row.get('Modelo')
        version = row.get('Versi√≥n')
        titulo = str(row.get('T√≠tulo', '')).lower()

        # Paso 0: normalizar posibles campos
        modelo_norm = str(modelo).lower() if pd.notna(modelo) else None
        version_norm = str(version).lower() if pd.notna(version) else None

        # Paso 1: Fuzzy matching por MODELO (cutoff alto)
        if modelo_norm:
            posibles = referencia[referencia['Modelo'].notna()]
            matches = get_close_matches(modelo_norm, posibles['Modelo'].str.lower().tolist(), n=1, cutoff=0.7)
            if matches:
                match_modelo = matches[0]
                marcas = posibles[posibles['Modelo'].str.lower() == match_modelo]['Marca']
                if not marcas.empty:
                    marca_inferida = marcas.mode().iloc[0]
                    print(f"[{idx + 2}] Fuzzy por MODELO: '{modelo_norm}' ‚âà '{match_modelo}' ‚Üí Marca: {marca_inferida} ({marcas.value_counts().to_dict()})")

        # Paso 2: Fuzzy matching por VERSI√ìN (cutoff alto)
        if not marca_inferida and version_norm:
            posibles = referencia[referencia['Versi√≥n'].notna()]
            matches = get_close_matches(version_norm, posibles['Versi√≥n'].str.lower().tolist(), n=1, cutoff=0.8)
            if matches:
                match_version = matches[0]
                marcas = posibles[posibles['Versi√≥n'].str.lower() == match_version]['Marca']
                if not marcas.empty:
                    marca_inferida = marcas.mode().iloc[0]
                    print(f"[{idx + 2}] Fuzzy por VERSI√ìN: '{version_norm}' ‚âà '{match_version}' ‚Üí Marca: {marca_inferida} ({marcas.value_counts().to_dict()})")

        # Paso 3: Segundo intento con cutoff m√°s bajo en MODELO
        if not marca_inferida and modelo_norm:
            matches = get_close_matches(modelo_norm, referencia['Modelo'].dropna().str.lower().tolist(), n=1, cutoff=0.5)
            if matches:
                match_modelo = matches[0]
                marcas = referencia[referencia['Modelo'].str.lower() == match_modelo]['Marca']
                if not marcas.empty:
                    marca_inferida = marcas.mode().iloc[0]
                    print(f"[{idx + 2}] Segundo intento MODELO (cutoff 0.5): '{modelo_norm}' ‚âà '{match_modelo}' ‚Üí Marca: {marca_inferida}")

        # Paso 4: Buscar en T√çTULO
        if not marca_inferida:
            for m in referencia['Marca'].unique():
                if pd.notna(m) and m.lower() in titulo:
                    marca_inferida = m.lower()
                    print(f"[{idx + 2}] Marca detectada en T√çTULO: '{marca_inferida}'")
                    break

        # Asignaci√≥n o eliminaci√≥n
        if marca_inferida:
            df.at[idx, 'Marca'] = marca_inferida
            reemplazos.append(idx)
        else:
            df.drop(index=idx, inplace=True)

    df_result = df[df['Marca'].notna()]
    print(f"\n‚úîÔ∏è Muestras imputadas: {len(reemplazos)}")
    print(f"üóëÔ∏è Muestras eliminadas por no poder imputar: {total_before - df_result.shape[0]}")
    return df_result


def hmv_modelo(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Modelo' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Si hay Marca y Versi√≥n: busca versiones asociadas a modelos v√°lidos de esa marca
    - Si no hay Marca pero s√≠ Versi√≥n: hace fuzzy matching sobre todas las versiones
    - Si no hay Versi√≥n: elimina la fila
    """

    df = df_to_input.copy()
    referencia = df_train[df_train['Modelo'].notna() & df_train['Versi√≥n'].notna()].copy()
    total_before = df.shape[0]

    df_missing = df[df['Modelo'].isna()].copy()
    print(f"üîç √çndices con modelo faltante: {[i + 2 for i in df_missing.index.tolist()]}")

    reemplazos = []
    for idx, row in df_missing.iterrows():
        modelo_inferido = None
        marca = str(row.get('Marca', '')).lower()
        version = str(row.get('Versi√≥n', '')).lower().strip()

        # Caso 1: no hay versi√≥n ‚Üí eliminar
        if not version:
            df.drop(index=idx, inplace=True)
            continue

        # Caso 2: hay marca v√°lida ‚Üí restringir a modelos de esa marca
        if marca in MODELOS_POR_MARCA:
            modelos_permitidos = MODELOS_POR_MARCA[marca]
            subset = referencia[referencia['Modelo'].str.lower().isin(modelos_permitidos)]
        else:
            # Caso 3: no hay marca o marca desconocida ‚Üí usar todo el entrenamiento
            subset = referencia

        if subset.empty:
            df.drop(index=idx, inplace=True)
            continue

        # Fuzzy matching con versiones
        versiones_entrenamiento = subset['Versi√≥n'].str.lower().tolist()
        matches = get_close_matches(version, versiones_entrenamiento, n=1, cutoff=0.7)

        if matches:
            match_version = matches[0]
            modelos_encontrados = subset[subset['Versi√≥n'].str.lower() == match_version]['Modelo']
            if not modelos_encontrados.empty:
                modelo_inferido = modelos_encontrados.mode().iloc[0]
                print(f"[{idx + 2}] Fuzzy por VERSI√ìN {'(con marca)' if marca in MODELOS_POR_MARCA else '(sin marca)'}: '{version}' ‚âà '{match_version}' ‚Üí Modelo: {modelo_inferido} ({modelos_encontrados.value_counts().to_dict()})")

        if modelo_inferido:
            df.at[idx, 'Modelo'] = modelo_inferido
            reemplazos.append(idx)
        else:
            df.drop(index=idx, inplace=True)

    df_result = df[df['Modelo'].notna()]
    print(f"\n‚úîÔ∏è Muestras imputadas: {len(reemplazos)}")
    print(f"üóëÔ∏è Muestras eliminadas por no poder imputar: {total_before - df_result.shape[0]}")
    return df_result




def hmv_version(df_train, df_to_input):
    """
    Imputa y agrupa versiones en df_to_input utilizando df_train como referencia.

    Paso 1: Imputaci√≥n
        - Si hay Modelo ‚Üí fuzzy matching con versiones de ese modelo en el train
        - Si no hay Modelo pero s√≠ Marca ‚Üí buscar versiones asociadas a los modelos de esa marca
        - Si no hay Marca ni Modelo ‚Üí eliminar fila

    Paso 2: Fuzzy clustering por modelo (agrupa si comparten tokens similares)
        - Agrupa versiones similares dentro de cada modelo
        - Asigna el nombre m√°s frecuente del grupo

    Paso 3: Agrupamiento final entre versiones resultantes del mismo modelo
        - Reagrupa versiones normalizadas que a√∫n sean similares entre s√≠
        - Usa fuzzy matching sobre strings completas


    COSAS A TENER EN CUENTA:
    - El paso 1 puede ser mejorado. Ahora solo aplica la moda, pero podr√≠a ser m√°s sofisticado teniendo en cuenta el precio, a√±o
     kilometraje, etc.
     - El paso 2 y 3 agrupan algunos casos que no deberian agruparse. Son similares semanticamente, pero tienen diferencias 
     importantes en el precio. Por ejemplo advance y advance plus.
    """

    df = df_to_input.copy()
    referencia = df_train[df_train['Versi√≥n'].notna()].copy()

    df_missing = df[df['Versi√≥n'].isna()].copy()
    print(f"üîç √çndices con versi√≥n faltante: {[i + 2 for i in df_missing.index.tolist()]}")

    reemplazos = []
    for idx, row in df_missing.iterrows():
        modelo = str(row.get("Modelo", "")).lower()
        marca = str(row.get("Marca", "")).lower()

        if modelo:
            versiones_posibles = referencia[referencia["Modelo"].str.lower() == modelo]["Versi√≥n"].dropna()
        elif marca in MODELOS_POR_MARCA:
            modelos_de_marca = MODELOS_POR_MARCA[marca]
            versiones_posibles = referencia[referencia["Modelo"].str.lower().isin(modelos_de_marca)]["Versi√≥n"].dropna()
        else:
            df.drop(index=idx, inplace=True)
            continue

        if versiones_posibles.empty:
            df.drop(index=idx, inplace=True)
            continue

        version_frecuente = versiones_posibles.mode().iloc[0]
        df.at[idx, "Versi√≥n"] = version_frecuente
        reemplazos.append(idx)
        print(f"[{idx + 2}] Imputada versi√≥n: '{version_frecuente}' usando contexto de {'modelo' if modelo else 'marca'}")

    df = df[df['Versi√≥n'].notna()]  # Eliminar filas sin imputar

    # Helper: chequea si dos cadenas comparten tokens similares
    def tokens_comparten_similitud(base, candidato, cutoff=0.8):
        tokens1 = base.replace('-', ' ').replace('_', ' ').lower().split()
        tokens2 = candidato.replace('-', ' ').replace('_', ' ').lower().split()
        for t1 in tokens1:
            if t1 in tokens2:
                return True
            if get_close_matches(t1, tokens2, n=1, cutoff=cutoff):
                return True
        return False

    # Paso 2: Clustering de versiones dentro de cada modelo
    versiones_normalizadas = {}

    for modelo, sub in df[['Modelo', 'Versi√≥n']].dropna().groupby('Modelo'):
        versiones = sub['Versi√≥n'].dropna().unique().tolist()
        mapeo = {}

        print(f"\nüîÑ Clustering de versiones para modelo: {modelo} ({len(versiones)} versiones distintas)")

        while versiones:
            base = versiones.pop(0)
            similares = []

            for v in versiones:
                if tokens_comparten_similitud(base, v, cutoff=0.8):
                    similares.append(v)

            grupo = [base] + similares
            versiones = [v for v in versiones if v not in similares]

            subset = sub[sub['Versi√≥n'].isin(grupo)]
            version_mas_comun = subset['Versi√≥n'].mode().iloc[0]

            if len(grupo) > 1:
                print(f"üë• Agrupadas: {grupo} ‚Üí üè∑Ô∏è '{version_mas_comun}'")

            for v in grupo:
                mapeo[v] = version_mas_comun

        for original, reemplazo in mapeo.items():
            versiones_normalizadas[(modelo, original)] = reemplazo

    # Aplicar los reemplazos de clustering
    def reemplazar_version(row):
        clave = (row['Modelo'], row['Versi√≥n'])
        return versiones_normalizadas.get(clave, row['Versi√≥n'])

    df['Versi√≥n'] = df.apply(reemplazar_version, axis=1)

    # Paso 3: Agrupamiento final entre versiones ya normalizadas (por modelo)
    print("\nüß© Paso final: Agrupamiento entre versiones ya normalizadas")

    def tokens_similares(v1, v2, cutoff=0.8):
        """
        Devuelve True si v1 y v2 comparten tokens similares (no necesita ser exacto).
        """
        tokens1 = v1.replace('-', ' ').replace('_', ' ').lower().split()
        tokens2 = v2.replace('-', ' ').replace('_', ' ').lower().split()
        for t1 in tokens1:
            if t1 in tokens2:
                return True
            if get_close_matches(t1, tokens2, n=1, cutoff=cutoff):
                return True
        return False

    for modelo, sub in df[['Modelo', 'Versi√≥n']].dropna().groupby('Modelo'):
        versiones_finales = sub['Versi√≥n'].unique().tolist()
        finales_map = {}

        print(f"\nüîç Agrupamiento final para modelo: {modelo} ({len(versiones_finales)} versiones)")

        while versiones_finales:
            base = versiones_finales.pop(0)
            similares = []

            for v in versiones_finales:
                if tokens_similares(base, v, cutoff=0.8):
                    similares.append(v)

            grupo = [base] + similares
            versiones_finales = [v for v in versiones_finales if v not in similares]

            subset = sub[sub['Versi√≥n'].isin(grupo)]
            version_final = subset['Versi√≥n'].mode().iloc[0]

            if len(grupo) > 1:
                print(f"üîó Agrupadas finales por token: {grupo} ‚Üí üè∑Ô∏è '{version_final}'")

            for v in grupo:
                finales_map[(modelo, v)] = version_final

        # Aplicar mapeo final
        def ajustar_version_final(row):
            clave = (row['Modelo'], row['Versi√≥n'])
            return finales_map.get(clave, row['Versi√≥n'])

        df['Versi√≥n'] = df.apply(ajustar_version_final, axis=1)


    print(f"\n‚úîÔ∏è Muestras imputadas: {len(reemplazos)}")
    print(f"üóëÔ∏è Muestras eliminadas por no poder imputar: {df_missing.shape[0] - len(reemplazos)}")
    return df


def hmv_combustible(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Tipo de combustible' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles (Marca, Modelo, Versi√≥n, A√±o).
    - Si no encuentra coincidencias, reduce las columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si no logra imputar, elimina la fila y la guarda en 'combustible_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Tipo de combustible'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Tipo de combustible'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Tipo de combustible'].mode()
                    if not moda.empty:
                        df.at[idx, 'Tipo de combustible'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'combustible_deleted.csv')")
    return df

def hmv_puertas(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Puertas' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles (Marca, Modelo, Versi√≥n, A√±o).
    - Si no encuentra coincidencias, reduce las columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si no logra imputar, elimina la fila y la guarda en 'puertas_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Puertas'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Puertas'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Puertas'].mode()
                    if not moda.empty:
                        df.at[idx, 'Puertas'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'puertas_deleted.csv')")
    return df

def hmv_transmision(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Transmisi√≥n' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para poder imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles.
    - Si no encuentra coincidencias, reduce el conjunto de columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si no logra imputar, elimina la fila y la guarda en 'transmision_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Transmisi√≥n'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Transmisi√≥n'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Transmisi√≥n'].mode()
                    if not moda.empty:
                        df.at[idx, 'Transmisi√≥n'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'transmision_deleted.csv')")
    return df



def hmv_motor(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Motor' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para poder imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles.
    - Si no encuentra coincidencias, reduce el conjunto de columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si no logra imputar, elimina la fila y la guarda en 'motor_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Motor'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Motor'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue  # Requiere al menos Modelo o Versi√≥n

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Motor'].mode()
                    if not moda.empty:
                        df.at[idx, 'Motor'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'motor_deleted.csv')")
    return df

def hmv_camara(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Con c√°mara de retroceso' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Solo intenta imputar si est√°n presentes Marca, Modelo, Versi√≥n y A√±o.
    - Busca coincidencias exactas con esas cuatro columnas en df_train o imputaciones anteriores.
    - Si hay coincidencias, asigna la moda.
    - Si no hay coincidencias, asigna 0.
    """
    import pandas as pd

    df = df_to_input.copy()
    referencia = df_train[df_train['Con c√°mara de retroceso'].notna()].copy()
    imputados = 0
    default_0 = 0

    for idx, row in df[df['Con c√°mara de retroceso'].isna()].iterrows():
        if any(pd.isna(row[col]) for col in ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']):
            print(f"[{idx + 2}] ‚ùå Faltan columnas clave. Se asigna 0.")
            df.at[idx, 'Con c√°mara de retroceso'] = 0
            default_0 += 1
            continue

        filtro = referencia[
            (referencia['Marca'] == row['Marca']) &
            (referencia['Modelo'] == row['Modelo']) &
            (referencia['Versi√≥n'] == row['Versi√≥n']) &
            (referencia['A√±o'] == row['A√±o'])
        ]

        print(f"[{idx + 2}] üîç Buscando coincidencias exactas en Marca, Modelo, Versi√≥n y A√±o")
        print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

        if not filtro.empty:
            moda = filtro['Con c√°mara de retroceso'].mode()
            if not moda.empty:
                valor = moda.iloc[0]
                df.at[idx, 'Con c√°mara de retroceso'] = valor
                print(f"   ‚úÖ Imputado con valor: {valor}")
                imputados += 1
            else:
                df.at[idx, 'Con c√°mara de retroceso'] = 0
                print(f"   ‚ö†Ô∏è Sin moda. Se asigna 0.")
                default_0 += 1
        else:
            df.at[idx, 'Con c√°mara de retroceso'] = 0
            print(f"   ‚ùå Sin coincidencias. Se asigna 0.")
            default_0 += 1

    print(f"\n‚úîÔ∏è Imputaciones realizadas por coincidencia exacta: {imputados}")
    print(f"üîß Muestras sin coincidencias (asignadas 0): {default_0}")

    return df


def hmv_hp(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'HP' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Busca combinaciones exactas con columnas: Motor, Versi√≥n, Modelo, A√±o, Marca (en ese orden de prioridad).
    - Eval√∫a combinaciones desde 5 hasta 1 columna, priorizando las que incluyan 'Motor'.
    - Requiere al menos uno entre 'Modelo', 'Versi√≥n' o 'Motor'.
    - Imputa la moda si encuentra coincidencias.
    - Si no encuentra coincidencias, elimina la muestra y la guarda en 'hp_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['HP'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Motor', 'Versi√≥n', 'Modelo', 'A√±o', 'Marca']

    for idx, row in df[df['HP'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n', 'Motor']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin al menos Modelo, Versi√≥n o Motor.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            posibles_subsets = list(combinations(disponibles, k))
            posibles_subsets.sort(key=lambda s: 'Motor' not in s)

            for subset in posibles_subsets:
                if not any(c in subset for c in ['Modelo', 'Versi√≥n', 'Motor']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['HP'].mode()
                    if not moda.empty:
                        df.at[idx, 'HP'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar. Se eliminar√° la muestra.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} ")
    return df



def hmv_traccion(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Tracci√≥n' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n'.
    - Busca coincidencias exactas con combinaciones de columnas disponibles: Marca, Modelo, Versi√≥n, A√±o.
    - Eval√∫a combinaciones desde 4 hasta 1 columna.
    - Si no encuentra coincidencias, asigna "4x2" como valor por defecto.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Tracci√≥n'].notna()].copy()
    imputados = 0
    asignados_default = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Tracci√≥n'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n. Se asigna '4x2'.")
            df.at[idx, 'Tracci√≥n'] = '4x2'
            asignados_default += 1
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(c in subset for c in ['Modelo', 'Versi√≥n']):
                    continue  # Requiere al menos Modelo o Versi√≥n

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Tracci√≥n'].mode()
                    if not moda.empty:
                        df.at[idx, 'Tracci√≥n'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            df.at[idx, 'Tracci√≥n'] = '4x2'
            print(f"   ‚ùå No se pudo imputar. Se asigna valor por defecto: '4x2'.")
            asignados_default += 1

    print(f"\n‚úîÔ∏è Imputaciones realizadas por coincidencia: {imputados}")
    print(f"üîß Asignaciones por defecto ('4x2'): {asignados_default}")

    return df

def hmv_year(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'A√±o' de df_to_input usando regresi√≥n lineal
    entrenada con muestras de df_train que coincidan en Marca, Modelo y Versi√≥n.

    Requiere que Kil√≥metros y Precio est√©n presentes.

    - Si hay al menos 5 coincidencias con a√±o conocido, se entrena una regresi√≥n.
    - Si no hay suficientes coincidencias o faltan predictores, se mantiene NaN.

    Retorna:
        pd.DataFrame con los valores imputados en la columna 'A√±o'.
    """
    import pandas as pd
    from sklearn.linear_model import LinearRegression
    import numpy as np

    df = df_to_input.copy()
    referencia = df_train[df_train['A√±o'].notna()].copy()
    imputados = 0

    for idx, row in df[df['A√±o'].isna()].iterrows():
        print(f"\n[{idx + 2}] üîç Intentando imputar A√±o para muestra:")

        if pd.isna(row['Kil√≥metros']) or pd.isna(row['Precio']):
            print(f"   ‚ö†Ô∏è Faltan datos clave (Kil√≥metros o Precio). Se omite.")
            continue

        print(f"   Marca: {row['Marca']}, Modelo: {row['Modelo']}, Versi√≥n: {row['Versi√≥n']}")
        print(f"   Kil√≥metros: {row['Kil√≥metros']}, Precio: {row['Precio']}")

        condiciones = (
            (referencia['Marca'] == row['Marca']) &
            (referencia['Modelo'] == row['Modelo']) &
            (referencia['Versi√≥n'] == row['Versi√≥n']) &
            referencia['Kil√≥metros'].notna() &
            referencia['Precio'].notna()
        )

        candidatos = referencia[condiciones]

        print(f"   ‚Ü™Ô∏è Coincidencias para regresi√≥n: {len(candidatos)}")

        if len(candidatos) < 5:
            print("   ‚ùå No hay suficientes datos para entrenar regresi√≥n.")
            continue

        X = candidatos[['Kil√≥metros', 'Precio']]
        y = candidatos['A√±o']

        modelo = LinearRegression()
        modelo.fit(X, y)

        pred = modelo.predict([[row['Kil√≥metros'], row['Precio']]])[0]
        pred_redondeado = int(round(pred))

        print(f"   ‚úÖ Predicci√≥n cruda: {pred:.2f} ‚Üí Imputado como: {pred_redondeado}")

        df.at[idx, 'A√±o'] = pred_redondeado
        imputados += 1

    print(f"\n‚úîÔ∏è A√±os imputados por regresi√≥n: {imputados}")
    return df

def hmv_km(df_train, df_to_input, min_size=15, max_ext=10):
    """
    Detecta outliers en 'Kil√≥metros' de df_to_input bas√°ndose en la distribuci√≥n de df_train.
    Marca los valores outlier como NaN en df_to_input y los imputa con la media del a√±o
    (expandiendo hacia a√±os vecinos si es necesario).

    Returns:
        df_result: copia de df_to_input con valores imputados en 'Kil√≥metros'
    """
    import pandas as pd

    def ajustar_rangos_iqr(grupo, a√±o):
        """
        Calcula l√≠mites de kilometraje adaptativos en funci√≥n de la antig√ºedad del auto.
        """
        Q1 = grupo['Kil√≥metros'].quantile(0.30)
        Q3 = grupo['Kil√≥metros'].quantile(0.70)
        IQR = Q3 - Q1
        antiguedad = 2025 - a√±o

        if antiguedad >= 30:
            factor_lower = 1.5
            factor_upper = 1.0
        elif antiguedad >= 20:
            factor_lower = 1.3
            factor_upper = 1.2
        elif antiguedad >= 10:
            factor_lower = 1.1
            factor_upper = 1.3
        elif antiguedad >= 3:
            factor_lower = 1.0
            factor_upper = 1.5
        else:
            factor_lower = 0.8
            factor_upper = 1.75

        lower = max(0, Q1 - factor_lower * IQR)
        upper = Q3 + factor_upper * IQR

        if antiguedad <= 1:
            upper = max(upper, 10000)

        return lower, upper

    df_result = df_to_input.copy()
    a√±os_unicos = sorted(df_result['A√±o'].dropna().unique())
    evaluados = set()

    outliers_total = 0
    imputados_total = 0
    no_imputados = 0

    print("üö® Paso 1: Detectando y marcando outliers seg√∫n df_train...\n")

    for a√±o in a√±os_unicos:
        if a√±o in evaluados:
            continue

        a√±o = int(a√±o)
        ext = 0
        grupo = pd.DataFrame()
        while ext <= max_ext:
            rango = list(range(a√±o - ext, a√±o + ext + 1))
            grupo = df_train[df_train['A√±o'].isin(rango)]
            if len(grupo) >= min_size:
                break
            ext += 1

        if len(grupo) < min_size:
            print(f"‚ö†Ô∏è A√±o {a√±o}: No se encontr√≥ suficiente data en train ni con expansi√≥n ¬±{max_ext}. Se omite.")
            continue

        lower, upper = ajustar_rangos_iqr(grupo, a√±o)
        evaluados.update(rango)

        print(f"‚úÖ A√±o {a√±o}: usando ventana ¬±{ext} ‚Üí {len(grupo)} muestras | Rango: {int(lower)} ‚Äì {int(upper)} km")

        cond_outlier = (
            (df_result['A√±o'] == a√±o) &
            ((df_result['Kil√≥metros'] < lower) | (df_result['Kil√≥metros'] > upper))
        )
        outliers_detectados = cond_outlier.sum()
        outliers_total += outliers_detectados
        df_result.loc[cond_outlier, 'Kil√≥metros'] = pd.NA

        print(f"   ‚Ü≥ {outliers_detectados} valores marcados como NaN en df_to_input\n")

    print("üõ†Ô∏è Paso 2: Imputando los NaN con medias de df_train...\n")

    for idx, row in df_result[df_result['Kil√≥metros'].isna()].iterrows():
        a√±o = int(row['A√±o'])
        ext = 0
        grupo = pd.DataFrame()

        while ext <= max_ext:
            rango = list(range(a√±o - ext, a√±o + ext + 1))
            grupo = df_train[
                (df_train['A√±o'].isin(rango)) &
                (df_train['Kil√≥metros'].notna())
            ]
            if len(grupo) >= min_size:
                break
            ext += 1

        if len(grupo) >= min_size:
            imputado = round(grupo['Kil√≥metros'].median())
            df_result.at[idx, 'Kil√≥metros'] = imputado
            imputados_total += 1
            print(f"üîÑ Imputado fila {idx} (a√±o {a√±o}) con media {imputado} km usando ventana ¬±{ext}")
        else:
            no_imputados += 1
            print(f"‚ö†Ô∏è No se pudo imputar fila {idx} (a√±o {a√±o}): insuficiente data en train incluso con expansi√≥n")

    print("\nüìä Estad√≠sticas finales:")
    print(f"üîç Total de valores marcados como outliers: {outliers_total}")
    print(f"üõ†Ô∏è Total de valores imputados exitosamente: {imputados_total}")
    print(f"üö´ Total de valores que quedaron como NaN: {no_imputados}")
    print("\n‚úÖ Proceso completo sin data leakage.\n")

    return df_result



def hmv_precio(df_train, df_to_input, min_size=10):
    """
    Detecta y reemplaza outliers en la columna 'Precio' en df_to_input,
    usando como referencia df_train y segmentando por Marca, Modelo, Versi√≥n, A√±o y un rango din√°mico de Kil√≥metros.

    Los outliers son marcados y reemplazados por:
    - mediana del grupo si hay suficientes datos.
    - Si no hay suficientes datos, intenta con la mediana de Marca+Modelo+Versi√≥n+A√±o.
    - Si a√∫n as√≠ no hay datos, deja el valor como est√°.
    - Si el valor original era NaN, se imputa con la mediana general del dataset.

    Args:
        df_train: DataFrame de referencia (train set sin data leakage).
        df_to_input: DataFrame sobre el cual imputar outliers en 'Precio'.
        min_size: m√≠nimo de coincidencias necesarias para calcular IQR.

    Returns:
        df_result: copia de df_to_input con 'Precio' imputado/redondeado cuando era outlier o faltante.
    """
    import pandas as pd
    import numpy as np

    df_result = df_to_input.copy()
    mediana_general = df_train['Precio'].median()

    modificados = 0
    imputados_fallback = 0
    imputados_generales = 0

    print("üö® Detectando e imputando outliers en 'Precio'...\n")

    for idx, row in df_result.iterrows():
        marca, modelo, version, a√±o, km, precio = row[['Marca', 'Modelo', 'Versi√≥n', 'A√±o', 'Kil√≥metros', 'Precio']]

        if pd.isna(km) or pd.isna(a√±o):
            continue  # no se puede evaluar

        # üß† Tolerancia de kil√≥metros seg√∫n antig√ºedad
        antiguedad = 2025 - int(a√±o)
        if km == 0:
            km_tol = 0
        elif antiguedad <= 1:
            km_tol = 1500
        elif antiguedad <= 5:
            km_tol = 5000
        elif antiguedad <= 10:
            km_tol = 10000
        else:
            km_tol = 20000

        # üéØ Grupo para detectar outliers
        grupo = df_train[
            (df_train['Marca'] == marca) &
            (df_train['Modelo'] == modelo) &
            (df_train['Versi√≥n'] == version) &
            (df_train['A√±o'] == a√±o) &
            (df_train['Kil√≥metros'].between(km - km_tol, km + km_tol)) &
            (df_train['Precio'].notna())
        ]

        if not pd.isna(precio) and len(grupo) >= min_size:
            Q1 = grupo['Precio'].quantile(0.25)
            Q3 = grupo['Precio'].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 1.5 * IQR
            upper = Q3 + 1.5 * IQR

            if precio < lower or precio > upper:
                imputado = round(grupo['Precio'].median())
                print(f"üîé Fila {idx}: ${precio:,.0f} fuera de rango [{int(lower)} ‚Äì {int(upper)}] ‚Üí imputado con mediana del grupo: ${imputado}")
                df_result.at[idx, 'Precio'] = imputado
                modificados += 1
        else:
            # üîÅ Fallback con Marca+Modelo+Versi√≥n+A√±o
            grupo_fallback = df_train[
                (df_train['Marca'] == marca) &
                (df_train['Modelo'] == modelo) &
                (df_train['Versi√≥n'] == version) &
                (df_train['A√±o'] == a√±o) &
                (df_train['Precio'].notna())
            ]

            if pd.isna(precio):
                if not grupo_fallback.empty:
                    imputado = round(grupo_fallback['Precio'].median())
                    print(f"‚ö†Ô∏è Fila {idx}: Precio faltante ‚Üí imputado con mediana del grupo fallback: ${imputado}")
                    df_result.at[idx, 'Precio'] = imputado
                    imputados_fallback += 1
                else:
                    imputado = round(mediana_general)
                    print(f"‚ö†Ô∏è Fila {idx}: Precio faltante y sin fallback ‚Üí imputado con mediana general: ${imputado}")
                    df_result.at[idx, 'Precio'] = imputado
                    imputados_generales += 1

    n_total = len(df_result)
    n_nan = df_result['Precio'].isna().sum()

    print("\nüìä Estad√≠sticas finales:")
    print(f"üîß Valores modificados por ser outliers: {modificados}")
    print(f"ü™õ Valores imputados por fallback (Marca+Modelo+Versi√≥n+A√±o): {imputados_fallback}")
    print(f"üßÆ Valores imputados con media general del dataset: {imputados_generales}")
    print(f"‚ùì Valores que siguen como NaN: {n_nan} / {n_total}")

    print("\n‚úÖ Proceso completado sin data leakage.\n")
    return df_result



def hmv_tipo_de_vendedor(df_train, df_to_input):
    """
    Imputa valores faltantes en 'Tipo de vendedor' de df_to_input usando como referencia df_train.
    Para cada valor NaN, busca la moda en el grupo coincidente por Marca + Modelo + Versi√≥n + A√±o.

    Args:
        df_train: DataFrame de referencia (con valores conocidos).
        df_to_input: DataFrame a imputar.

    Returns:
        df_result: copia de df_to_input con imputaciones aplicadas.
    """
    import pandas as pd

    df_result = df_to_input.copy()
    imputados = 0

    for idx, row in df_result[df_result['Tipo de vendedor'].isna()].iterrows():
        marca = row['Marca']
        modelo = row['Modelo']
        version = row['Versi√≥n']
        a√±o = row['A√±o']

        grupo = df_train[
            (df_train['Marca'] == marca) &
            (df_train['Modelo'] == modelo) &
            (df_train['Versi√≥n'] == version) &
            (df_train['A√±o'] == a√±o) &
            (df_train['Tipo de vendedor'].notna())
        ]

        if not grupo.empty:
            moda = grupo['Tipo de vendedor'].mode().iloc[0]
            df_result.at[idx, 'Tipo de vendedor'] = moda
            imputados += 1

    print(f"‚úÖ Imputaciones completadas: {imputados} valores reemplazados.\n")
    return df_result



def hmv_color(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Color' y agrupa valores similares bas√°ndose en tokens con similitud textual.
    Orden de operaciones:
    1. Imputaci√≥n de valores faltantes en 'Color' en df_to_input usando df_train (prioridad: Versi√≥n > Modelo > Marca)
    2. Reemplazo de 'morado' por 'violeta' en ambos datasets
    3. Agrupamiento de colores por tokens similares usando df_train
    4. Reemplazo de valores conocidos en df_to_input seg√∫n el agrupamiento
    """

    # Copia de df_to_input
    df_result = df_to_input.copy()

    # ü©π Paso 1: Imputando valores faltantes con prioridad Versi√≥n ‚Üí Modelo ‚Üí Marca
    print("ü©π Paso 1: Imputando valores faltantes con prioridad Versi√≥n ‚Üí Modelo ‚Üí Marca\n")
    imputados = 0
    for idx, row in df_result[df_result['Color'].isna()].iterrows():
        version = row.get('Versi√≥n')
        modelo = row.get('Modelo')
        marca = row.get('Marca')

        valor_color = None

        # Intento 1: por versi√≥n (usar df_train)
        if pd.notna(version):
            coincidencias = df_train[df_train['Versi√≥n'] == version]['Color'].dropna()
            if not coincidencias.empty:
                valor_color = coincidencias.mode().iloc[0]
                origen = 'versi√≥n'

        # Intento 2: por modelo (usar df_train)
        if valor_color is None and pd.notna(modelo):
            coincidencias = df_train[df_train['Modelo'] == modelo]['Color'].dropna()
            if not coincidencias.empty:
                valor_color = coincidencias.mode().iloc[0]
                origen = 'modelo'

        # Intento 3: por marca (usar df_train)
        if valor_color is None and pd.notna(marca):
            coincidencias = df_train[df_train['Marca'] == marca]['Color'].dropna()
            if not coincidencias.empty:
                valor_color = coincidencias.mode().iloc[0]
                origen = 'marca'

        if valor_color is not None:
            df_result.at[idx, 'Color'] = valor_color
            imputados += 1
            print(f"[{idx + 2}] üñåÔ∏è Imputado color '{valor_color}' por {origen}")
        else:
            print(f"[{idx + 2}] ‚ö†Ô∏è No se pudo imputar. Se mantiene como NaN")

    print(f"\n‚úÖ Total de colores imputados por contexto: {imputados}\n")

    # üé® Paso 2: Reemplazando 'morado' por 'violeta' en ambos datasets
    print("üé® Paso 2: Reemplazando 'morado' por 'violeta' en ambos datasets...\n")
    for df in [df_train, df_result]:
        df['Color'] = df['Color'].apply(lambda c: 'violeta' if isinstance(c, str) and 'morado' in normalizar(c, eliminar_espacios=False) else c)

    # üîç Paso 3: Agrupando colores por tokens similares
    print("üîç Paso 3: Agrupando colores por tokens similares...\n")
    colores = df_train['Color'].dropna().unique()
    token_map = {}
    color_groups = {}

    for color in colores:
        tokens = normalizar(color, eliminar_espacios=False).split()
        if not tokens:
            continue
        first_token = tokens[0].strip()
        if not first_token:
            continue
        similars = get_close_matches(first_token, token_map.keys(), n=1, cutoff=0.7)
        if similars:
            group_key = token_map[similars[0]]
        else:
            group_key = first_token
        token_map[first_token] = group_key
        color_groups.setdefault(group_key, set()).add(color)

    print(f"üì¶ Grupos de colores formados: {len(color_groups)}")
    for grupo, variantes in color_groups.items():
        print(f"üîó Token base: '{grupo}' ‚Üí {sorted(variantes)}")

    # üßº Paso 4: Reemplazando valores conocidos en df_to_input seg√∫n agrupamiento
    print("\nüßº Paso 4: Reemplazando valores conocidos en df_to_input seg√∫n agrupamiento...\n")
    color_map = {}
    for grupo, variantes in color_groups.items():
        for variante in variantes:
            color_map[variante] = grupo

    df_result['Color'] = df_result['Color'].map(lambda x: color_map.get(x, x))

    return df_result




def hmv_dataset(df_train, df_to_input):
    """
    Ejecuta en orden todas las funciones hmv_* para imputar datos faltantes
    sobre df_to_input, utilizando df_train como referencia.
    """
    original_count = len(df_to_input)
    df = df_to_input.copy()

    # Lista de funciones de imputaci√≥n hmv
    hmv_funcs = [
        ("hmv_marca", hmv_marca),
        ("hmv_modelo", hmv_modelo),
        ("hmv_version", hmv_version),
        ("hmv_combustible", hmv_combustible),
        ("hmv_puertas", hmv_puertas),
        ("hmv_transmision", hmv_transmision),
        ("hmv_motor", hmv_motor),
        ("hmv_camara", hmv_camara),
        ("hmv_hp", hmv_hp),
        ("hmv_traccion", hmv_traccion),
        ("hmv_year", hmv_year),
        ("hmv_km", hmv_km),
        ("hmv_precio", hmv_precio),
        ("hmv_tipo_de_vendedor", hmv_tipo_de_vendedor),  
        ("hmv_color", hmv_color),
    ]

    for func_name, func in hmv_funcs:
        count_before = len(df)
        df = func(df_train, df)
        count_after = len(df)
        if count_after < count_before:
            print(f"[{func_name}] Muestras eliminadas: {count_before - count_after}")

    total_eliminadas = original_count - len(df)
    print(f"[TOTAL] Muestras eliminadas en total: {total_eliminadas}")

    return df