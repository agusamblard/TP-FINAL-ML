from difflib import get_close_matches
import pandas as pd
from utils.diccionarios import MARCAS_VALIDAS, MODELOS_POR_MARCA
from preprocessing.data_cleanse import normalizar, quitar_tildes
import re
def hmv_marca(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Marca' en df_to_input usando df_train como referencia.
    - Primero intenta imputar por fuzzy matching con 'Modelo' (cutoff alto)
    - Luego intenta con 'Versi√≥n' (cutoff alto)
    - Si falla, intenta fuzzy con cutoff m√°s bajo
    - Luego intenta detectar marca en 'T√≠tulo'
    - Si todo falla, elimina la fila
    Prints:
    - √çndices con marca faltante (+2)
    - Coincidencias encontradas y marcas asignadas
    - √çndices de filas eliminadas (+2)
    - Resumen final
    """
    df = df_to_input.copy()
    referencia = df_train[df_train['Marca'].notna()].copy()
    total_before = df.shape[0]

    df_missing = df[df['Marca'].isna()].copy()
    print(f"üîç √çndices con marca faltante: {[i + 2 for i in df_missing.index.tolist()]}")

    reemplazos = []
    for idx, row in df_missing.iterrows():
        marca_inferida = None
        modelo = row.get('Modelo')
        version = row.get('Versi√≥n')
        titulo = str(row.get('T√≠tulo', '')).lower()

        # Paso 0: normalizar posibles campos
        modelo_norm = str(modelo).lower() if pd.notna(modelo) else None
        version_norm = str(version).lower() if pd.notna(version) else None

        # Paso 1: Fuzzy matching por MODELO (cutoff alto)
        if modelo_norm:
            posibles = referencia[referencia['Modelo'].notna()]
            matches = get_close_matches(modelo_norm, posibles['Modelo'].str.lower().tolist(), n=1, cutoff=0.7)
            if matches:
                match_modelo = matches[0]
                marcas = posibles[posibles['Modelo'].str.lower() == match_modelo]['Marca']
                if not marcas.empty:
                    marca_inferida = marcas.mode().iloc[0]
                    print(f"[{idx + 2}] Fuzzy por MODELO: '{modelo_norm}' ‚âà '{match_modelo}' ‚Üí Marca: {marca_inferida} ({marcas.value_counts().to_dict()})")

        # Paso 2: Fuzzy matching por VERSI√ìN (cutoff alto)
        if not marca_inferida and version_norm:
            posibles = referencia[referencia['Versi√≥n'].notna()]
            matches = get_close_matches(version_norm, posibles['Versi√≥n'].str.lower().tolist(), n=1, cutoff=0.8)
            if matches:
                match_version = matches[0]
                marcas = posibles[posibles['Versi√≥n'].str.lower() == match_version]['Marca']
                if not marcas.empty:
                    marca_inferida = marcas.mode().iloc[0]
                    print(f"[{idx + 2}] Fuzzy por VERSI√ìN: '{version_norm}' ‚âà '{match_version}' ‚Üí Marca: {marca_inferida} ({marcas.value_counts().to_dict()})")

        # Paso 3: Segundo intento con cutoff m√°s bajo en MODELO
        if not marca_inferida and modelo_norm:
            matches = get_close_matches(modelo_norm, referencia['Modelo'].dropna().str.lower().tolist(), n=1, cutoff=0.5)
            if matches:
                match_modelo = matches[0]
                marcas = referencia[referencia['Modelo'].str.lower() == match_modelo]['Marca']
                if not marcas.empty:
                    marca_inferida = marcas.mode().iloc[0]
                    print(f"[{idx + 2}] Segundo intento MODELO (cutoff 0.5): '{modelo_norm}' ‚âà '{match_modelo}' ‚Üí Marca: {marca_inferida}")

        # Paso 4: Buscar en T√çTULO
        if not marca_inferida:
            for m in referencia['Marca'].unique():
                if pd.notna(m) and m.lower() in titulo:
                    marca_inferida = m.lower()
                    print(f"[{idx + 2}] Marca detectada en T√çTULO: '{marca_inferida}'")
                    break

        # Asignaci√≥n o eliminaci√≥n
        if marca_inferida:
            df.at[idx, 'Marca'] = marca_inferida
            reemplazos.append(idx)
        else:
            df.drop(index=idx, inplace=True)

    df_result = df[df['Marca'].notna()]
    print(f"\n‚úîÔ∏è Muestras imputadas: {len(reemplazos)}")
    print(f"üóëÔ∏è Muestras eliminadas por no poder imputar: {total_before - df_result.shape[0]}")
    return df_result


def hmv_modelo(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Modelo' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Si hay Marca y Versi√≥n: busca versiones asociadas a modelos v√°lidos de esa marca
    - Si no hay Marca pero s√≠ Versi√≥n: hace fuzzy matching sobre todas las versiones
    - Si no hay Versi√≥n: elimina la fila
    """

    df = df_to_input.copy()
    referencia = df_train[df_train['Modelo'].notna() & df_train['Versi√≥n'].notna()].copy()
    total_before = df.shape[0]

    df_missing = df[df['Modelo'].isna()].copy()
    print(f"üîç √çndices con modelo faltante: {[i + 2 for i in df_missing.index.tolist()]}")

    reemplazos = []
    for idx, row in df_missing.iterrows():
        modelo_inferido = None
        marca = str(row.get('Marca', '')).lower()
        version = str(row.get('Versi√≥n', '')).lower().strip()

        # Caso 1: no hay versi√≥n ‚Üí eliminar
        if not version:
            df.drop(index=idx, inplace=True)
            continue

        # Caso 2: hay marca v√°lida ‚Üí restringir a modelos de esa marca
        if marca in MODELOS_POR_MARCA:
            modelos_permitidos = MODELOS_POR_MARCA[marca]
            subset = referencia[referencia['Modelo'].str.lower().isin(modelos_permitidos)]
        else:
            # Caso 3: no hay marca o marca desconocida ‚Üí usar todo el entrenamiento
            subset = referencia

        if subset.empty:
            df.drop(index=idx, inplace=True)
            continue

        # Fuzzy matching con versiones
        versiones_entrenamiento = subset['Versi√≥n'].str.lower().tolist()
        matches = get_close_matches(version, versiones_entrenamiento, n=1, cutoff=0.7)

        if matches:
            match_version = matches[0]
            modelos_encontrados = subset[subset['Versi√≥n'].str.lower() == match_version]['Modelo']
            if not modelos_encontrados.empty:
                modelo_inferido = modelos_encontrados.mode().iloc[0]
                print(f"[{idx + 2}] Fuzzy por VERSI√ìN {'(con marca)' if marca in MODELOS_POR_MARCA else '(sin marca)'}: '{version}' ‚âà '{match_version}' ‚Üí Modelo: {modelo_inferido} ({modelos_encontrados.value_counts().to_dict()})")

        if modelo_inferido:
            df.at[idx, 'Modelo'] = modelo_inferido
            reemplazos.append(idx)
        else:
            df.drop(index=idx, inplace=True)

    df_result = df[df['Modelo'].notna()]
    print(f"\n‚úîÔ∏è Muestras imputadas: {len(reemplazos)}")
    print(f"üóëÔ∏è Muestras eliminadas por no poder imputar: {total_before - df_result.shape[0]}")
    return df_result




def hmv_version(df_train, df_to_input):
    """
    Imputa y agrupa versiones en df_to_input utilizando df_train como referencia.

    Paso 1: Imputaci√≥n
        - Si hay Modelo ‚Üí fuzzy matching con versiones de ese modelo en el train
        - Si no hay Modelo pero s√≠ Marca ‚Üí buscar versiones asociadas a los modelos de esa marca
        - Si no hay Marca ni Modelo ‚Üí eliminar fila

    Paso 2: Fuzzy clustering por modelo (agrupa si comparten tokens similares)
        - Agrupa versiones similares dentro de cada modelo
        - Asigna el nombre m√°s frecuente del grupo

    Paso 3: Agrupamiento final entre versiones resultantes del mismo modelo
        - Reagrupa versiones normalizadas que a√∫n sean similares entre s√≠
        - Usa fuzzy matching sobre strings completas


    COSAS A TENER EN CUENTA:
    - El paso 1 puede ser mejorado. Ahora solo aplica la moda, pero podr√≠a ser m√°s sofisticado teniendo en cuenta el precio, a√±o
     kilometraje, etc.
     - El paso 2 y 3 agrupan algunos casos que no deberian agruparse. Son similares semanticamente, pero tienen diferencias 
     importantes en el precio. Por ejemplo advance y advance plus.
    """

    df = df_to_input.copy()
    referencia = df_train[df_train['Versi√≥n'].notna()].copy()

    df_missing = df[df['Versi√≥n'].isna()].copy()
    print(f"üîç √çndices con versi√≥n faltante: {[i + 2 for i in df_missing.index.tolist()]}")

    reemplazos = []
    for idx, row in df_missing.iterrows():
        modelo = str(row.get("Modelo", "")).lower()
        marca = str(row.get("Marca", "")).lower()

        if modelo:
            versiones_posibles = referencia[referencia["Modelo"].str.lower() == modelo]["Versi√≥n"].dropna()
        elif marca in MODELOS_POR_MARCA:
            modelos_de_marca = MODELOS_POR_MARCA[marca]
            versiones_posibles = referencia[referencia["Modelo"].str.lower().isin(modelos_de_marca)]["Versi√≥n"].dropna()
        else:
            df.drop(index=idx, inplace=True)
            continue

        if versiones_posibles.empty:
            df.drop(index=idx, inplace=True)
            continue

        version_frecuente = versiones_posibles.mode().iloc[0]
        df.at[idx, "Versi√≥n"] = version_frecuente
        reemplazos.append(idx)
        print(f"[{idx + 2}] Imputada versi√≥n: '{version_frecuente}' usando contexto de {'modelo' if modelo else 'marca'}")

    df = df[df['Versi√≥n'].notna()]  # Eliminar filas sin imputar

    # Helper: chequea si dos cadenas comparten tokens similares
    def tokens_comparten_similitud(base, candidato, cutoff=0.8):
        tokens1 = base.replace('-', ' ').replace('_', ' ').lower().split()
        tokens2 = candidato.replace('-', ' ').replace('_', ' ').lower().split()
        for t1 in tokens1:
            if t1 in tokens2:
                return True
            if get_close_matches(t1, tokens2, n=1, cutoff=cutoff):
                return True
        return False

    # Paso 2: Clustering de versiones dentro de cada modelo
    versiones_normalizadas = {}

    for modelo, sub in df[['Modelo', 'Versi√≥n']].dropna().groupby('Modelo'):
        versiones = sub['Versi√≥n'].dropna().unique().tolist()
        mapeo = {}

        print(f"\nüîÑ Clustering de versiones para modelo: {modelo} ({len(versiones)} versiones distintas)")

        while versiones:
            base = versiones.pop(0)
            similares = []

            for v in versiones:
                if tokens_comparten_similitud(base, v, cutoff=0.8):
                    similares.append(v)

            grupo = [base] + similares
            versiones = [v for v in versiones if v not in similares]

            subset = sub[sub['Versi√≥n'].isin(grupo)]
            version_mas_comun = subset['Versi√≥n'].mode().iloc[0]

            if len(grupo) > 1:
                print(f"üë• Agrupadas: {grupo} ‚Üí üè∑Ô∏è '{version_mas_comun}'")

            for v in grupo:
                mapeo[v] = version_mas_comun

        for original, reemplazo in mapeo.items():
            versiones_normalizadas[(modelo, original)] = reemplazo

    # Aplicar los reemplazos de clustering
    def reemplazar_version(row):
        clave = (row['Modelo'], row['Versi√≥n'])
        return versiones_normalizadas.get(clave, row['Versi√≥n'])

    df['Versi√≥n'] = df.apply(reemplazar_version, axis=1)

    # Paso 3: Agrupamiento final entre versiones ya normalizadas (por modelo)
    print("\nüß© Paso final: Agrupamiento entre versiones ya normalizadas")

    def tokens_similares(v1, v2, cutoff=0.8):
        """
        Devuelve True si v1 y v2 comparten tokens similares (no necesita ser exacto).
        """
        tokens1 = v1.replace('-', ' ').replace('_', ' ').lower().split()
        tokens2 = v2.replace('-', ' ').replace('_', ' ').lower().split()
        for t1 in tokens1:
            if t1 in tokens2:
                return True
            if get_close_matches(t1, tokens2, n=1, cutoff=cutoff):
                return True
        return False

    for modelo, sub in df[['Modelo', 'Versi√≥n']].dropna().groupby('Modelo'):
        versiones_finales = sub['Versi√≥n'].unique().tolist()
        finales_map = {}

        print(f"\nüîç Agrupamiento final para modelo: {modelo} ({len(versiones_finales)} versiones)")

        while versiones_finales:
            base = versiones_finales.pop(0)
            similares = []

            for v in versiones_finales:
                if tokens_similares(base, v, cutoff=0.8):
                    similares.append(v)

            grupo = [base] + similares
            versiones_finales = [v for v in versiones_finales if v not in similares]

            subset = sub[sub['Versi√≥n'].isin(grupo)]
            version_final = subset['Versi√≥n'].mode().iloc[0]

            if len(grupo) > 1:
                print(f"üîó Agrupadas finales por token: {grupo} ‚Üí üè∑Ô∏è '{version_final}'")

            for v in grupo:
                finales_map[(modelo, v)] = version_final

        # Aplicar mapeo final
        def ajustar_version_final(row):
            clave = (row['Modelo'], row['Versi√≥n'])
            return finales_map.get(clave, row['Versi√≥n'])

        df['Versi√≥n'] = df.apply(ajustar_version_final, axis=1)


    print(f"\n‚úîÔ∏è Muestras imputadas: {len(reemplazos)}")
    print(f"üóëÔ∏è Muestras eliminadas por no poder imputar: {df_missing.shape[0] - len(reemplazos)}")
    return df


def hmv_combustible(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Tipo de combustible' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles (Marca, Modelo, Versi√≥n, A√±o).
    - Si no encuentra coincidencias, reduce las columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si logra imputar, agrega la muestra al set de referencia.
    - Si no logra imputar, elimina la fila y la guarda en 'combustible_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Tipo de combustible'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Tipo de combustible'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Tipo de combustible'].mode()
                    if not moda.empty:
                        df.at[idx, 'Tipo de combustible'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'combustible_deleted.csv')")
    return df

def hmv_puertas(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Puertas' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles (Marca, Modelo, Versi√≥n, A√±o).
    - Si no encuentra coincidencias, reduce las columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si logra imputar, agrega la muestra al set de referencia.
    - Si no logra imputar, elimina la fila y la guarda en 'puertas_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Puertas'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Puertas'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Puertas'].mode()
                    if not moda.empty:
                        df.at[idx, 'Puertas'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'puertas_deleted.csv')")
    return df

def hmv_transmision(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Transmisi√≥n' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para poder imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles.
    - Si no encuentra coincidencias, reduce el conjunto de columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si logra imputar, agrega la muestra al set de referencia.
    - Si no logra imputar, elimina la fila y la guarda en 'transmision_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Transmisi√≥n'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Transmisi√≥n'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Transmisi√≥n'].mode()
                    if not moda.empty:
                        df.at[idx, 'Transmisi√≥n'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'transmision_deleted.csv')")
    return df



def hmv_motor(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Motor' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n' para poder imputar.
    - Busca coincidencias exactas con las columnas no nulas disponibles.
    - Si no encuentra coincidencias, reduce el conjunto de columnas (manteniendo Modelo/Versi√≥n) hasta encontrar alguna.
    - Si logra imputar, la muestra se agrega al set de referencia para futuras imputaciones.
    - Si no logra imputar, elimina la fila y la guarda en 'motor_deleted.csv'.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Motor'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Motor'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(col in subset for col in ['Modelo', 'Versi√≥n']):
                    continue  # Requiere al menos Modelo o Versi√≥n

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Motor'].mode()
                    if not moda.empty:
                        df.at[idx, 'Motor'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar, se eliminar√°.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} (guardadas en 'motor_deleted.csv')")
    return df

def hmv_camara(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Con c√°mara de retroceso' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Solo intenta imputar si est√°n presentes Marca, Modelo, Versi√≥n y A√±o.
    - Busca coincidencias exactas con esas cuatro columnas en df_train o imputaciones anteriores.
    - Si hay coincidencias, asigna la moda.
    - Si no hay coincidencias, asigna 0.
    - Imputaciones exitosas se agregan al set de referencia paso a paso.
    """
    import pandas as pd

    df = df_to_input.copy()
    referencia = df_train[df_train['Con c√°mara de retroceso'].notna()].copy()
    imputados = 0
    default_0 = 0

    for idx, row in df[df['Con c√°mara de retroceso'].isna()].iterrows():
        if any(pd.isna(row[col]) for col in ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']):
            print(f"[{idx + 2}] ‚ùå Faltan columnas clave. Se asigna 0.")
            df.at[idx, 'Con c√°mara de retroceso'] = 0
            default_0 += 1
            continue

        filtro = referencia[
            (referencia['Marca'] == row['Marca']) &
            (referencia['Modelo'] == row['Modelo']) &
            (referencia['Versi√≥n'] == row['Versi√≥n']) &
            (referencia['A√±o'] == row['A√±o'])
        ]

        print(f"[{idx + 2}] üîç Buscando coincidencias exactas en Marca, Modelo, Versi√≥n y A√±o")
        print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

        if not filtro.empty:
            moda = filtro['Con c√°mara de retroceso'].mode()
            if not moda.empty:
                valor = moda.iloc[0]
                df.at[idx, 'Con c√°mara de retroceso'] = valor
                print(f"   ‚úÖ Imputado con valor: {valor}")
                imputados += 1
            else:
                df.at[idx, 'Con c√°mara de retroceso'] = 0
                print(f"   ‚ö†Ô∏è Sin moda. Se asigna 0.")
                default_0 += 1
        else:
            df.at[idx, 'Con c√°mara de retroceso'] = 0
            print(f"   ‚ùå Sin coincidencias. Se asigna 0.")
            default_0 += 1

    print(f"\n‚úîÔ∏è Imputaciones realizadas por coincidencia exacta: {imputados}")
    print(f"üîß Muestras sin coincidencias (asignadas 0): {default_0}")

    return df


def hmv_hp(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'HP' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Busca combinaciones exactas con columnas: Motor, Versi√≥n, Modelo, A√±o, Marca (en ese orden de prioridad).
    - Eval√∫a combinaciones desde 5 hasta 1 columna, priorizando las que incluyan 'Motor'.
    - Requiere al menos uno entre 'Modelo', 'Versi√≥n' o 'Motor'.
    - Imputa la moda si encuentra coincidencias.
    - Si no encuentra coincidencias, elimina la muestra y la guarda en 'hp_deleted.csv'.
    - Las imputaciones exitosas se agregan a la base de referencia en cada paso.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['HP'].notna()].copy()
    imputados = 0

    columnas_importancia = ['Motor', 'Versi√≥n', 'Modelo', 'A√±o', 'Marca']

    for idx, row in df[df['HP'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n', 'Motor']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin al menos Modelo, Versi√≥n o Motor.")
            df.drop(index=idx, inplace=True)
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            posibles_subsets = list(combinations(disponibles, k))
            posibles_subsets.sort(key=lambda s: 'Motor' not in s)

            for subset in posibles_subsets:
                if not any(c in subset for c in ['Modelo', 'Versi√≥n', 'Motor']):
                    continue

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['HP'].mode()
                    if not moda.empty:
                        df.at[idx, 'HP'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            print(f"   ‚ùå No se pudo imputar. Se eliminar√° la muestra.")
            df.drop(index=idx, inplace=True)

    print(f"\n‚úîÔ∏è Imputaciones realizadas: {imputados}")
    print(f"üóëÔ∏è Muestras eliminadas: {df_to_input.shape[0] - df.shape[0]} ")
    return df



def hmv_traccion(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'Tracci√≥n' de df_to_input usando df_train como referencia.

    L√≥gica:
    - Requiere al menos 'Modelo' o 'Versi√≥n'.
    - Busca coincidencias exactas con combinaciones de columnas disponibles: Marca, Modelo, Versi√≥n, A√±o.
    - Eval√∫a combinaciones desde 4 hasta 1 columna.
    - Si encuentra coincidencias, imputa la moda y actualiza el set de referencia.
    - Si no encuentra coincidencias, asigna "4x2" como valor por defecto.
    """
    import pandas as pd
    from itertools import combinations

    df = df_to_input.copy()
    referencia = df_train[df_train['Tracci√≥n'].notna()].copy()
    imputados = 0
    asignados_default = 0

    columnas_importancia = ['Marca', 'Modelo', 'Versi√≥n', 'A√±o']

    for idx, row in df[df['Tracci√≥n'].isna()].iterrows():
        disponibles = [col for col in columnas_importancia if pd.notna(row.get(col))]

        if not disponibles or not any(col in disponibles for col in ['Modelo', 'Versi√≥n']):
            print(f"[{idx + 2}] ‚ùå No se puede imputar sin Modelo o Versi√≥n. Se asigna '4x2'.")
            df.at[idx, 'Tracci√≥n'] = '4x2'
            asignados_default += 1
            continue

        imputado = False

        for k in range(len(disponibles), 0, -1):
            for subset in combinations(disponibles, k):
                if not any(c in subset for c in ['Modelo', 'Versi√≥n']):
                    continue  # Requiere al menos Modelo o Versi√≥n

                filtro = referencia.copy()
                for col in subset:
                    filtro = filtro[filtro[col] == row[col]]

                print(f"[{idx + 2}] üîç Buscando con columnas: {', '.join(subset)}")
                print(f"   ‚Ü™Ô∏è Coincidencias encontradas: {len(filtro)}")

                if not filtro.empty:
                    moda = filtro['Tracci√≥n'].mode()
                    if not moda.empty:
                        df.at[idx, 'Tracci√≥n'] = moda.iloc[0]
                        print(f"   ‚úÖ Imputado con valor: {moda.iloc[0]}")
                        imputados += 1
                        imputado = True
                        break
            if imputado:
                break

        if not imputado:
            df.at[idx, 'Tracci√≥n'] = '4x2'
            print(f"   ‚ùå No se pudo imputar. Se asigna valor por defecto: '4x2'.")
            asignados_default += 1

    print(f"\n‚úîÔ∏è Imputaciones realizadas por coincidencia: {imputados}")
    print(f"üîß Asignaciones por defecto ('4x2'): {asignados_default}")

    return df

def hmv_year(df_train, df_to_input):
    """
    Imputa valores faltantes en la columna 'A√±o' de df_to_input usando regresi√≥n lineal
    entrenada con muestras de df_train que coincidan en Marca, Modelo y Versi√≥n.

    Requiere que Kil√≥metros y Precio est√©n presentes.

    - Si hay al menos 5 coincidencias con a√±o conocido, se entrena una regresi√≥n.
    - Si no hay suficientes coincidencias o faltan predictores, se mantiene NaN.

    Retorna:
        pd.DataFrame con los valores imputados en la columna 'A√±o'.
    """
    import pandas as pd
    from sklearn.linear_model import LinearRegression
    import numpy as np

    df = df_to_input.copy()
    referencia = df_train[df_train['A√±o'].notna()].copy()
    imputados = 0

    for idx, row in df[df['A√±o'].isna()].iterrows():
        print(f"\n[{idx + 2}] üîç Intentando imputar A√±o para muestra:")

        if pd.isna(row['Kil√≥metros']) or pd.isna(row['Precio']):
            print(f"   ‚ö†Ô∏è Faltan datos clave (Kil√≥metros o Precio). Se omite.")
            continue

        print(f"   Marca: {row['Marca']}, Modelo: {row['Modelo']}, Versi√≥n: {row['Versi√≥n']}")
        print(f"   Kil√≥metros: {row['Kil√≥metros']}, Precio: {row['Precio']}")

        condiciones = (
            (referencia['Marca'] == row['Marca']) &
            (referencia['Modelo'] == row['Modelo']) &
            (referencia['Versi√≥n'] == row['Versi√≥n']) &
            referencia['Kil√≥metros'].notna() &
            referencia['Precio'].notna()
        )

        candidatos = referencia[condiciones]

        print(f"   ‚Ü™Ô∏è Coincidencias para regresi√≥n: {len(candidatos)}")

        if len(candidatos) < 5:
            print("   ‚ùå No hay suficientes datos para entrenar regresi√≥n.")
            continue

        X = candidatos[['Kil√≥metros', 'Precio']]
        y = candidatos['A√±o']

        modelo = LinearRegression()
        modelo.fit(X, y)

        pred = modelo.predict([[row['Kil√≥metros'], row['Precio']]])[0]
        pred_redondeado = int(round(pred))

        print(f"   ‚úÖ Predicci√≥n cruda: {pred:.2f} ‚Üí Imputado como: {pred_redondeado}")

        df.at[idx, 'A√±o'] = pred_redondeado
        imputados += 1

    print(f"\n‚úîÔ∏è A√±os imputados por regresi√≥n: {imputados}")
    return df

def hmv_km(df_train, df_to_input):
    '''
    HAY QUE IMPLEMENTARLO. QUIEOR ANALIZAR CORRELACION PARA VER SI SE PUEDE HACER UNA REGRESION
    
    '''
    return df_to_input

def hmv_precio(df_train, df_to_input):
    '''
    HAY QUE IMPLEMENTARLO. QUIEOR ANALIZAR CORRELACION PARA VER SI SE PUEDE HACER UNA REGRESION
    
    '''
    return df_to_input

def hmv_tipo_de_vendedor(df_train,df_to_input):
    '''
    HAY QUE IMPLEMENTARLO. QUIEOR ANALIZAR CORRELACION PARA VER SI SE PUEDE HACER UNA REGRESION

    '''
    return df_to_input


def hmv_color(df_train, df_to_input):
    """
    Agrupa valores similares en la columna 'Color' bas√°ndose en tokens con similitud textual.
    Luego imputa NaNs utilizando este orden de prioridad:
    1. Moda de 'Color' para esa Versi√≥n
    2. Moda de 'Color' para ese Modelo
    3. Moda de 'Color' para esa Marca
    """

    print("üé® Paso 0: Reemplazando 'morado' por 'violeta' en ambos datasets...\n")
    for df in [df_train, df_to_input]:
        df['Color'] = df['Color'].apply(lambda c: 'violeta' if isinstance(c, str) and 'morado' in normalizar(c, eliminar_espacios=False) else c)

    print("üîç Paso 1: Agrupando colores por tokens similares...\n")
    colores = df_train['Color'].dropna().unique()
    token_map = {}
    color_groups = {}

    for color in colores:
        tokens = normalizar(color, eliminar_espacios=False).split()
        if not tokens:
            continue
        first_token = tokens[0].strip()
        if not first_token:
            continue
        similars = get_close_matches(first_token, token_map.keys(), n=1, cutoff=0.7)
        if similars:
            group_key = token_map[similars[0]]
        else:
            group_key = first_token
        token_map[first_token] = group_key
        color_groups.setdefault(group_key, set()).add(color)

    print(f"üì¶ Grupos de colores formados: {len(color_groups)}")
    for grupo, variantes in color_groups.items():
        print(f"üîó Token base: '{grupo}' ‚Üí {sorted(variantes)}")

    print("\nüßº Paso 2: Reemplazando valores conocidos en df_to_input...\n")
    color_map = {}
    for grupo, variantes in color_groups.items():
        for variante in variantes:
            color_map[variante] = grupo

    df_result = df_to_input.copy()
    df_result['Color'] = df_result['Color'].map(lambda x: color_map.get(x, x))

    print("ü©π Paso 3: Imputando valores faltantes con prioridad Versi√≥n ‚Üí Modelo ‚Üí Marca\n")
    imputados = 0
    for idx, row in df_result[df_result['Color'].isna()].iterrows():
        version = row.get('Versi√≥n')
        modelo = row.get('Modelo')
        marca = row.get('Marca')

        valor_color = None

        # Intento 1: por versi√≥n
        if pd.notna(version):
            coincidencias = df_result[df_result['Versi√≥n'] == version]['Color'].dropna()
            if not coincidencias.empty:
                valor_color = coincidencias.mode().iloc[0]
                origen = 'versi√≥n'

        # Intento 2: por modelo
        if valor_color is None and pd.notna(modelo):
            coincidencias = df_result[df_result['Modelo'] == modelo]['Color'].dropna()
            if not coincidencias.empty:
                valor_color = coincidencias.mode().iloc[0]
                origen = 'modelo'

        # Intento 3: por marca
        if valor_color is None and pd.notna(marca):
            coincidencias = df_result[df_result['Marca'] == marca]['Color'].dropna()
            if not coincidencias.empty:
                valor_color = coincidencias.mode().iloc[0]
                origen = 'marca'

        if valor_color is not None:
            df_result.at[idx, 'Color'] = valor_color
            imputados += 1
            print(f"[{idx + 2}] üñåÔ∏è Imputado color '{valor_color}' por {origen}")
        else:
            print(f"[{idx + 2}] ‚ö†Ô∏è No se pudo imputar. Se mantiene como NaN")

    print(f"\n‚úÖ Total de colores imputados por contexto: {imputados}")
    return df_result




def hmv_dataset(df_train, df_to_input):
    """
    Ejecuta en orden todas las funciones hmv_* para imputar datos faltantes
    sobre df_to_input, utilizando df_train como referencia.
    """
    original_count = len(df_to_input)
    df = df_to_input.copy()

    # Lista de funciones de imputaci√≥n hmv
    hmv_funcs = [
        ("hmv_marca", hmv_marca),
        ("hmv_modelo", hmv_modelo),
        ("hmv_version", hmv_version),
        ("hmv_combustible", hmv_combustible),
        ("hmv_puertas", hmv_puertas),
        ("hmv_transmision", hmv_transmision),
        ("hmv_motor", hmv_motor),
        ("hmv_camara", hmv_camara),
        ("hmv_hp", hmv_hp),
        ("hmv_traccion", hmv_traccion),
        ("hmv_year", hmv_year),
        ("hmv_km", hmv_km),  # a√∫n sin implementar
        ("hmv_precio", hmv_precio),  # a√∫n sin implementar
        ("hmv_tipo_de_vendedor", hmv_tipo_de_vendedor),  # a√∫n sin implementar
        ("hmv_color", hmv_color),
    ]

    for func_name, func in hmv_funcs:
        count_before = len(df)
        df = func(df_train, df)
        count_after = len(df)
        if count_after < count_before:
            print(f"[{func_name}] Muestras eliminadas: {count_before - count_after}")

    total_eliminadas = original_count - len(df)
    print(f"[TOTAL] Muestras eliminadas en total: {total_eliminadas}")

    return df